{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Deep_FFN_with_TF_2_0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pritam17/MyProject1/blob/master/Deep_FFN_with_TF_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzi40tPcbuwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0OVYA7c4EZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV0muaq74S14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1=np.random.randint(1,30,200000)\n",
        "x2=np.random.randint(1,30,200000)\n",
        "x=pd.DataFrame({'x1':x1,'x2':x2})\n",
        "y=4+2*x1+3*x2+3*np.random.random(200000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk3ZYsd47Jwr",
        "colab_type": "code",
        "outputId": "f3b6f810-a23b-413c-cdb3-af5abe55761f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>15</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>24</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        x1  x2\n",
              "0       16  20\n",
              "1        5   4\n",
              "2       29  27\n",
              "3       17  15\n",
              "4       27  18\n",
              "...     ..  ..\n",
              "199995  21   8\n",
              "199996  10  16\n",
              "199997  15  28\n",
              "199998  19  11\n",
              "199999  24  29\n",
              "\n",
              "[200000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bneF_1Ru4ahT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class preds:\n",
        "    def __init__(self):\n",
        "        self.w1=tf.Variable(0.0)\n",
        "        self.w2=tf.Variable(0.0)\n",
        "        self.b=tf.Variable(0.0)\n",
        "    \n",
        "    def __call__(self,x):\n",
        "        result=self.w1*x.iloc[:,0]+self.w2*x.iloc[:,1]+self.b\n",
        "        return(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnYCMDyv4c-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=preds()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqyEfT9rPItj",
        "colab_type": "code",
        "outputId": "047f8ba1-6aef-4de3-a9bc-19d609ae6aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(200000,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KxRCz7H4gZ0",
        "colab_type": "code",
        "outputId": "4e94ab49-aefa-4b73-d85f-6c276026d273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model(x).numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYApB4rT4jec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(predicted_y, target_y):\n",
        "    return tf.reduce_mean(tf.square(predicted_y - target_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LdZ-Vra4mow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, inputs, outputs, learning_rate):\n",
        "    with tf.GradientTape() as t:\n",
        "        current_loss = loss(model(inputs), outputs)\n",
        "    dw1,dw2, db = t.gradient(current_loss, [model.w1,model.w2, model.b])\n",
        "    model.w1.assign_sub(learning_rate * dw1)\n",
        "    model.w2.assign_sub(learning_rate * dw2)\n",
        "    model.b.assign_sub(learning_rate * db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wmxwh6l4pOX",
        "colab_type": "code",
        "outputId": "3abed820-9e47-4158-d06f-64b274a9edc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = preds()\n",
        "\n",
        "# Collect the history of W-values and b-values to plot later\n",
        "w1s,w2s, bs = [], [],[]\n",
        "\n",
        "epochs = range(500)\n",
        "for epoch in epochs:\n",
        "      for j in range(0,np.int(x.shape[0]/100),100):\n",
        "        inputs=x.iloc[j:j+100,:]\n",
        "        outputs=y[j:j+100]\n",
        "        train(model, inputs, outputs, learning_rate=0.001)\n",
        "      w1s.append(model.w1.numpy())\n",
        "      w2s.append(model.w2.numpy())\n",
        "      bs.append(model.b.numpy())\n",
        "    \n",
        "    # rand_ind=np.random.choice(range(x.shape[0]),100)\n",
        "    # outputs=y[rand_ind]\n",
        "    # inputs=x.iloc[rand_ind,:]\n",
        "    \n",
        "      current_loss = loss(model(inputs), outputs)\n",
        "\n",
        "    \n",
        "      print('Epoch %2d: W1=%1.2f W2=%1.2f b=%1.2f, loss=%2.5f' %\n",
        "          (epoch, w1s[-1],w2s[-1], bs[-1], current_loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0: W1=2.17 W2=3.12 b=0.19, loss=3.90081\n",
            "Epoch  1: W1=2.15 W2=3.14 b=0.22, loss=3.93219\n",
            "Epoch  2: W1=2.15 W2=3.14 b=0.25, loss=3.90050\n",
            "Epoch  3: W1=2.15 W2=3.14 b=0.27, loss=3.86392\n",
            "Epoch  4: W1=2.15 W2=3.14 b=0.30, loss=3.82750\n",
            "Epoch  5: W1=2.15 W2=3.14 b=0.33, loss=3.79147\n",
            "Epoch  6: W1=2.15 W2=3.14 b=0.36, loss=3.75584\n",
            "Epoch  7: W1=2.15 W2=3.14 b=0.39, loss=3.72061\n",
            "Epoch  8: W1=2.15 W2=3.14 b=0.42, loss=3.68578\n",
            "Epoch  9: W1=2.15 W2=3.13 b=0.45, loss=3.65133\n",
            "Epoch 10: W1=2.14 W2=3.13 b=0.47, loss=3.61726\n",
            "Epoch 11: W1=2.14 W2=3.13 b=0.50, loss=3.58358\n",
            "Epoch 12: W1=2.14 W2=3.13 b=0.53, loss=3.55027\n",
            "Epoch 13: W1=2.14 W2=3.13 b=0.56, loss=3.51733\n",
            "Epoch 14: W1=2.14 W2=3.13 b=0.58, loss=3.48477\n",
            "Epoch 15: W1=2.14 W2=3.13 b=0.61, loss=3.45256\n",
            "Epoch 16: W1=2.14 W2=3.13 b=0.64, loss=3.42071\n",
            "Epoch 17: W1=2.14 W2=3.13 b=0.66, loss=3.38922\n",
            "Epoch 18: W1=2.14 W2=3.13 b=0.69, loss=3.35808\n",
            "Epoch 19: W1=2.14 W2=3.13 b=0.72, loss=3.32728\n",
            "Epoch 20: W1=2.14 W2=3.13 b=0.74, loss=3.29684\n",
            "Epoch 21: W1=2.14 W2=3.13 b=0.77, loss=3.26673\n",
            "Epoch 22: W1=2.14 W2=3.13 b=0.80, loss=3.23696\n",
            "Epoch 23: W1=2.13 W2=3.12 b=0.82, loss=3.20752\n",
            "Epoch 24: W1=2.13 W2=3.12 b=0.85, loss=3.17841\n",
            "Epoch 25: W1=2.13 W2=3.12 b=0.87, loss=3.14962\n",
            "Epoch 26: W1=2.13 W2=3.12 b=0.90, loss=3.12116\n",
            "Epoch 27: W1=2.13 W2=3.12 b=0.92, loss=3.09301\n",
            "Epoch 28: W1=2.13 W2=3.12 b=0.95, loss=3.06518\n",
            "Epoch 29: W1=2.13 W2=3.12 b=0.98, loss=3.03766\n",
            "Epoch 30: W1=2.13 W2=3.12 b=1.00, loss=3.01044\n",
            "Epoch 31: W1=2.13 W2=3.12 b=1.02, loss=2.98353\n",
            "Epoch 32: W1=2.13 W2=3.12 b=1.05, loss=2.95693\n",
            "Epoch 33: W1=2.13 W2=3.12 b=1.07, loss=2.93061\n",
            "Epoch 34: W1=2.13 W2=3.12 b=1.10, loss=2.90459\n",
            "Epoch 35: W1=2.13 W2=3.12 b=1.12, loss=2.87887\n",
            "Epoch 36: W1=2.13 W2=3.12 b=1.15, loss=2.85343\n",
            "Epoch 37: W1=2.12 W2=3.11 b=1.17, loss=2.82828\n",
            "Epoch 38: W1=2.12 W2=3.11 b=1.19, loss=2.80341\n",
            "Epoch 39: W1=2.12 W2=3.11 b=1.22, loss=2.77881\n",
            "Epoch 40: W1=2.12 W2=3.11 b=1.24, loss=2.75449\n",
            "Epoch 41: W1=2.12 W2=3.11 b=1.27, loss=2.73045\n",
            "Epoch 42: W1=2.12 W2=3.11 b=1.29, loss=2.70666\n",
            "Epoch 43: W1=2.12 W2=3.11 b=1.31, loss=2.68315\n",
            "Epoch 44: W1=2.12 W2=3.11 b=1.34, loss=2.65990\n",
            "Epoch 45: W1=2.12 W2=3.11 b=1.36, loss=2.63691\n",
            "Epoch 46: W1=2.12 W2=3.11 b=1.38, loss=2.61418\n",
            "Epoch 47: W1=2.12 W2=3.11 b=1.40, loss=2.59170\n",
            "Epoch 48: W1=2.12 W2=3.11 b=1.43, loss=2.56948\n",
            "Epoch 49: W1=2.12 W2=3.11 b=1.45, loss=2.54751\n",
            "Epoch 50: W1=2.12 W2=3.11 b=1.47, loss=2.52577\n",
            "Epoch 51: W1=2.12 W2=3.11 b=1.49, loss=2.50429\n",
            "Epoch 52: W1=2.11 W2=3.11 b=1.52, loss=2.48304\n",
            "Epoch 53: W1=2.11 W2=3.10 b=1.54, loss=2.46203\n",
            "Epoch 54: W1=2.11 W2=3.10 b=1.56, loss=2.44125\n",
            "Epoch 55: W1=2.11 W2=3.10 b=1.58, loss=2.42071\n",
            "Epoch 56: W1=2.11 W2=3.10 b=1.60, loss=2.40040\n",
            "Epoch 57: W1=2.11 W2=3.10 b=1.62, loss=2.38032\n",
            "Epoch 58: W1=2.11 W2=3.10 b=1.65, loss=2.36046\n",
            "Epoch 59: W1=2.11 W2=3.10 b=1.67, loss=2.34083\n",
            "Epoch 60: W1=2.11 W2=3.10 b=1.69, loss=2.32142\n",
            "Epoch 61: W1=2.11 W2=3.10 b=1.71, loss=2.30222\n",
            "Epoch 62: W1=2.11 W2=3.10 b=1.73, loss=2.28323\n",
            "Epoch 63: W1=2.11 W2=3.10 b=1.75, loss=2.26447\n",
            "Epoch 64: W1=2.11 W2=3.10 b=1.77, loss=2.24591\n",
            "Epoch 65: W1=2.11 W2=3.10 b=1.79, loss=2.22756\n",
            "Epoch 66: W1=2.11 W2=3.10 b=1.81, loss=2.20941\n",
            "Epoch 67: W1=2.11 W2=3.10 b=1.83, loss=2.19147\n",
            "Epoch 68: W1=2.11 W2=3.10 b=1.85, loss=2.17373\n",
            "Epoch 69: W1=2.10 W2=3.10 b=1.87, loss=2.15619\n",
            "Epoch 70: W1=2.10 W2=3.10 b=1.89, loss=2.13885\n",
            "Epoch 71: W1=2.10 W2=3.09 b=1.91, loss=2.12170\n",
            "Epoch 72: W1=2.10 W2=3.09 b=1.93, loss=2.10474\n",
            "Epoch 73: W1=2.10 W2=3.09 b=1.95, loss=2.08798\n",
            "Epoch 74: W1=2.10 W2=3.09 b=1.97, loss=2.07140\n",
            "Epoch 75: W1=2.10 W2=3.09 b=1.99, loss=2.05501\n",
            "Epoch 76: W1=2.10 W2=3.09 b=2.01, loss=2.03880\n",
            "Epoch 77: W1=2.10 W2=3.09 b=2.03, loss=2.02277\n",
            "Epoch 78: W1=2.10 W2=3.09 b=2.05, loss=2.00693\n",
            "Epoch 79: W1=2.10 W2=3.09 b=2.07, loss=1.99126\n",
            "Epoch 80: W1=2.10 W2=3.09 b=2.09, loss=1.97577\n",
            "Epoch 81: W1=2.10 W2=3.09 b=2.11, loss=1.96045\n",
            "Epoch 82: W1=2.10 W2=3.09 b=2.13, loss=1.94531\n",
            "Epoch 83: W1=2.10 W2=3.09 b=2.14, loss=1.93033\n",
            "Epoch 84: W1=2.10 W2=3.09 b=2.16, loss=1.91553\n",
            "Epoch 85: W1=2.10 W2=3.09 b=2.18, loss=1.90089\n",
            "Epoch 86: W1=2.10 W2=3.09 b=2.20, loss=1.88642\n",
            "Epoch 87: W1=2.09 W2=3.09 b=2.22, loss=1.87211\n",
            "Epoch 88: W1=2.09 W2=3.09 b=2.24, loss=1.85795\n",
            "Epoch 89: W1=2.09 W2=3.09 b=2.25, loss=1.84396\n",
            "Epoch 90: W1=2.09 W2=3.08 b=2.27, loss=1.83013\n",
            "Epoch 91: W1=2.09 W2=3.08 b=2.29, loss=1.81644\n",
            "Epoch 92: W1=2.09 W2=3.08 b=2.31, loss=1.80292\n",
            "Epoch 93: W1=2.09 W2=3.08 b=2.33, loss=1.78955\n",
            "Epoch 94: W1=2.09 W2=3.08 b=2.34, loss=1.77633\n",
            "Epoch 95: W1=2.09 W2=3.08 b=2.36, loss=1.76326\n",
            "Epoch 96: W1=2.09 W2=3.08 b=2.38, loss=1.75033\n",
            "Epoch 97: W1=2.09 W2=3.08 b=2.39, loss=1.73755\n",
            "Epoch 98: W1=2.09 W2=3.08 b=2.41, loss=1.72492\n",
            "Epoch 99: W1=2.09 W2=3.08 b=2.43, loss=1.71242\n",
            "Epoch 100: W1=2.09 W2=3.08 b=2.45, loss=1.70007\n",
            "Epoch 101: W1=2.09 W2=3.08 b=2.46, loss=1.68786\n",
            "Epoch 102: W1=2.09 W2=3.08 b=2.48, loss=1.67578\n",
            "Epoch 103: W1=2.09 W2=3.08 b=2.50, loss=1.66384\n",
            "Epoch 104: W1=2.09 W2=3.08 b=2.51, loss=1.65204\n",
            "Epoch 105: W1=2.09 W2=3.08 b=2.53, loss=1.64037\n",
            "Epoch 106: W1=2.09 W2=3.08 b=2.55, loss=1.62883\n",
            "Epoch 107: W1=2.08 W2=3.08 b=2.56, loss=1.61742\n",
            "Epoch 108: W1=2.08 W2=3.08 b=2.58, loss=1.60614\n",
            "Epoch 109: W1=2.08 W2=3.08 b=2.59, loss=1.59498\n",
            "Epoch 110: W1=2.08 W2=3.08 b=2.61, loss=1.58395\n",
            "Epoch 111: W1=2.08 W2=3.08 b=2.63, loss=1.57305\n",
            "Epoch 112: W1=2.08 W2=3.07 b=2.64, loss=1.56227\n",
            "Epoch 113: W1=2.08 W2=3.07 b=2.66, loss=1.55161\n",
            "Epoch 114: W1=2.08 W2=3.07 b=2.67, loss=1.54108\n",
            "Epoch 115: W1=2.08 W2=3.07 b=2.69, loss=1.53066\n",
            "Epoch 116: W1=2.08 W2=3.07 b=2.71, loss=1.52036\n",
            "Epoch 117: W1=2.08 W2=3.07 b=2.72, loss=1.51017\n",
            "Epoch 118: W1=2.08 W2=3.07 b=2.74, loss=1.50010\n",
            "Epoch 119: W1=2.08 W2=3.07 b=2.75, loss=1.49015\n",
            "Epoch 120: W1=2.08 W2=3.07 b=2.77, loss=1.48030\n",
            "Epoch 121: W1=2.08 W2=3.07 b=2.78, loss=1.47057\n",
            "Epoch 122: W1=2.08 W2=3.07 b=2.80, loss=1.46095\n",
            "Epoch 123: W1=2.08 W2=3.07 b=2.81, loss=1.45144\n",
            "Epoch 124: W1=2.08 W2=3.07 b=2.83, loss=1.44203\n",
            "Epoch 125: W1=2.08 W2=3.07 b=2.84, loss=1.43273\n",
            "Epoch 126: W1=2.08 W2=3.07 b=2.86, loss=1.42354\n",
            "Epoch 127: W1=2.08 W2=3.07 b=2.87, loss=1.41445\n",
            "Epoch 128: W1=2.08 W2=3.07 b=2.88, loss=1.40547\n",
            "Epoch 129: W1=2.08 W2=3.07 b=2.90, loss=1.39658\n",
            "Epoch 130: W1=2.07 W2=3.07 b=2.91, loss=1.38780\n",
            "Epoch 131: W1=2.07 W2=3.07 b=2.93, loss=1.37911\n",
            "Epoch 132: W1=2.07 W2=3.07 b=2.94, loss=1.37053\n",
            "Epoch 133: W1=2.07 W2=3.07 b=2.96, loss=1.36204\n",
            "Epoch 134: W1=2.07 W2=3.07 b=2.97, loss=1.35365\n",
            "Epoch 135: W1=2.07 W2=3.07 b=2.98, loss=1.34535\n",
            "Epoch 136: W1=2.07 W2=3.06 b=3.00, loss=1.33714\n",
            "Epoch 137: W1=2.07 W2=3.06 b=3.01, loss=1.32903\n",
            "Epoch 138: W1=2.07 W2=3.06 b=3.03, loss=1.32102\n",
            "Epoch 139: W1=2.07 W2=3.06 b=3.04, loss=1.31309\n",
            "Epoch 140: W1=2.07 W2=3.06 b=3.05, loss=1.30525\n",
            "Epoch 141: W1=2.07 W2=3.06 b=3.07, loss=1.29751\n",
            "Epoch 142: W1=2.07 W2=3.06 b=3.08, loss=1.28985\n",
            "Epoch 143: W1=2.07 W2=3.06 b=3.09, loss=1.28227\n",
            "Epoch 144: W1=2.07 W2=3.06 b=3.11, loss=1.27478\n",
            "Epoch 145: W1=2.07 W2=3.06 b=3.12, loss=1.26738\n",
            "Epoch 146: W1=2.07 W2=3.06 b=3.13, loss=1.26006\n",
            "Epoch 147: W1=2.07 W2=3.06 b=3.15, loss=1.25283\n",
            "Epoch 148: W1=2.07 W2=3.06 b=3.16, loss=1.24568\n",
            "Epoch 149: W1=2.07 W2=3.06 b=3.17, loss=1.23861\n",
            "Epoch 150: W1=2.07 W2=3.06 b=3.19, loss=1.23161\n",
            "Epoch 151: W1=2.07 W2=3.06 b=3.20, loss=1.22470\n",
            "Epoch 152: W1=2.07 W2=3.06 b=3.21, loss=1.21787\n",
            "Epoch 153: W1=2.07 W2=3.06 b=3.22, loss=1.21111\n",
            "Epoch 154: W1=2.07 W2=3.06 b=3.24, loss=1.20444\n",
            "Epoch 155: W1=2.07 W2=3.06 b=3.25, loss=1.19784\n",
            "Epoch 156: W1=2.06 W2=3.06 b=3.26, loss=1.19131\n",
            "Epoch 157: W1=2.06 W2=3.06 b=3.27, loss=1.18486\n",
            "Epoch 158: W1=2.06 W2=3.06 b=3.29, loss=1.17848\n",
            "Epoch 159: W1=2.06 W2=3.06 b=3.30, loss=1.17217\n",
            "Epoch 160: W1=2.06 W2=3.06 b=3.31, loss=1.16593\n",
            "Epoch 161: W1=2.06 W2=3.06 b=3.32, loss=1.15978\n",
            "Epoch 162: W1=2.06 W2=3.06 b=3.33, loss=1.15368\n",
            "Epoch 163: W1=2.06 W2=3.06 b=3.35, loss=1.14766\n",
            "Epoch 164: W1=2.06 W2=3.05 b=3.36, loss=1.14170\n",
            "Epoch 165: W1=2.06 W2=3.05 b=3.37, loss=1.13582\n",
            "Epoch 166: W1=2.06 W2=3.05 b=3.38, loss=1.13000\n",
            "Epoch 167: W1=2.06 W2=3.05 b=3.39, loss=1.12424\n",
            "Epoch 168: W1=2.06 W2=3.05 b=3.41, loss=1.11856\n",
            "Epoch 169: W1=2.06 W2=3.05 b=3.42, loss=1.11293\n",
            "Epoch 170: W1=2.06 W2=3.05 b=3.43, loss=1.10737\n",
            "Epoch 171: W1=2.06 W2=3.05 b=3.44, loss=1.10188\n",
            "Epoch 172: W1=2.06 W2=3.05 b=3.45, loss=1.09644\n",
            "Epoch 173: W1=2.06 W2=3.05 b=3.46, loss=1.09108\n",
            "Epoch 174: W1=2.06 W2=3.05 b=3.47, loss=1.08577\n",
            "Epoch 175: W1=2.06 W2=3.05 b=3.49, loss=1.08052\n",
            "Epoch 176: W1=2.06 W2=3.05 b=3.50, loss=1.07533\n",
            "Epoch 177: W1=2.06 W2=3.05 b=3.51, loss=1.07020\n",
            "Epoch 178: W1=2.06 W2=3.05 b=3.52, loss=1.06513\n",
            "Epoch 179: W1=2.06 W2=3.05 b=3.53, loss=1.06012\n",
            "Epoch 180: W1=2.06 W2=3.05 b=3.54, loss=1.05517\n",
            "Epoch 181: W1=2.06 W2=3.05 b=3.55, loss=1.05027\n",
            "Epoch 182: W1=2.06 W2=3.05 b=3.56, loss=1.04543\n",
            "Epoch 183: W1=2.06 W2=3.05 b=3.57, loss=1.04064\n",
            "Epoch 184: W1=2.06 W2=3.05 b=3.58, loss=1.03591\n",
            "Epoch 185: W1=2.06 W2=3.05 b=3.59, loss=1.03123\n",
            "Epoch 186: W1=2.05 W2=3.05 b=3.60, loss=1.02661\n",
            "Epoch 187: W1=2.05 W2=3.05 b=3.62, loss=1.02204\n",
            "Epoch 188: W1=2.05 W2=3.05 b=3.63, loss=1.01752\n",
            "Epoch 189: W1=2.05 W2=3.05 b=3.64, loss=1.01305\n",
            "Epoch 190: W1=2.05 W2=3.05 b=3.65, loss=1.00864\n",
            "Epoch 191: W1=2.05 W2=3.05 b=3.66, loss=1.00427\n",
            "Epoch 192: W1=2.05 W2=3.05 b=3.67, loss=0.99996\n",
            "Epoch 193: W1=2.05 W2=3.05 b=3.68, loss=0.99570\n",
            "Epoch 194: W1=2.05 W2=3.05 b=3.69, loss=0.99148\n",
            "Epoch 195: W1=2.05 W2=3.05 b=3.70, loss=0.98732\n",
            "Epoch 196: W1=2.05 W2=3.05 b=3.71, loss=0.98320\n",
            "Epoch 197: W1=2.05 W2=3.05 b=3.72, loss=0.97912\n",
            "Epoch 198: W1=2.05 W2=3.04 b=3.73, loss=0.97510\n",
            "Epoch 199: W1=2.05 W2=3.04 b=3.74, loss=0.97112\n",
            "Epoch 200: W1=2.05 W2=3.04 b=3.75, loss=0.96719\n",
            "Epoch 201: W1=2.05 W2=3.04 b=3.76, loss=0.96330\n",
            "Epoch 202: W1=2.05 W2=3.04 b=3.77, loss=0.95946\n",
            "Epoch 203: W1=2.05 W2=3.04 b=3.78, loss=0.95566\n",
            "Epoch 204: W1=2.05 W2=3.04 b=3.79, loss=0.95191\n",
            "Epoch 205: W1=2.05 W2=3.04 b=3.79, loss=0.94819\n",
            "Epoch 206: W1=2.05 W2=3.04 b=3.80, loss=0.94452\n",
            "Epoch 207: W1=2.05 W2=3.04 b=3.81, loss=0.94090\n",
            "Epoch 208: W1=2.05 W2=3.04 b=3.82, loss=0.93731\n",
            "Epoch 209: W1=2.05 W2=3.04 b=3.83, loss=0.93377\n",
            "Epoch 210: W1=2.05 W2=3.04 b=3.84, loss=0.93027\n",
            "Epoch 211: W1=2.05 W2=3.04 b=3.85, loss=0.92681\n",
            "Epoch 212: W1=2.05 W2=3.04 b=3.86, loss=0.92338\n",
            "Epoch 213: W1=2.05 W2=3.04 b=3.87, loss=0.92000\n",
            "Epoch 214: W1=2.05 W2=3.04 b=3.88, loss=0.91666\n",
            "Epoch 215: W1=2.05 W2=3.04 b=3.89, loss=0.91335\n",
            "Epoch 216: W1=2.05 W2=3.04 b=3.90, loss=0.91009\n",
            "Epoch 217: W1=2.05 W2=3.04 b=3.90, loss=0.90686\n",
            "Epoch 218: W1=2.05 W2=3.04 b=3.91, loss=0.90367\n",
            "Epoch 219: W1=2.05 W2=3.04 b=3.92, loss=0.90051\n",
            "Epoch 220: W1=2.05 W2=3.04 b=3.93, loss=0.89739\n",
            "Epoch 221: W1=2.05 W2=3.04 b=3.94, loss=0.89432\n",
            "Epoch 222: W1=2.04 W2=3.04 b=3.95, loss=0.89127\n",
            "Epoch 223: W1=2.04 W2=3.04 b=3.96, loss=0.88826\n",
            "Epoch 224: W1=2.04 W2=3.04 b=3.97, loss=0.88528\n",
            "Epoch 225: W1=2.04 W2=3.04 b=3.97, loss=0.88234\n",
            "Epoch 226: W1=2.04 W2=3.04 b=3.98, loss=0.87944\n",
            "Epoch 227: W1=2.04 W2=3.04 b=3.99, loss=0.87656\n",
            "Epoch 228: W1=2.04 W2=3.04 b=4.00, loss=0.87372\n",
            "Epoch 229: W1=2.04 W2=3.04 b=4.01, loss=0.87092\n",
            "Epoch 230: W1=2.04 W2=3.04 b=4.02, loss=0.86814\n",
            "Epoch 231: W1=2.04 W2=3.04 b=4.02, loss=0.86540\n",
            "Epoch 232: W1=2.04 W2=3.04 b=4.03, loss=0.86269\n",
            "Epoch 233: W1=2.04 W2=3.04 b=4.04, loss=0.86001\n",
            "Epoch 234: W1=2.04 W2=3.04 b=4.05, loss=0.85736\n",
            "Epoch 235: W1=2.04 W2=3.04 b=4.06, loss=0.85474\n",
            "Epoch 236: W1=2.04 W2=3.04 b=4.06, loss=0.85216\n",
            "Epoch 237: W1=2.04 W2=3.04 b=4.07, loss=0.84960\n",
            "Epoch 238: W1=2.04 W2=3.04 b=4.08, loss=0.84707\n",
            "Epoch 239: W1=2.04 W2=3.03 b=4.09, loss=0.84458\n",
            "Epoch 240: W1=2.04 W2=3.03 b=4.10, loss=0.84211\n",
            "Epoch 241: W1=2.04 W2=3.03 b=4.10, loss=0.83967\n",
            "Epoch 242: W1=2.04 W2=3.03 b=4.11, loss=0.83726\n",
            "Epoch 243: W1=2.04 W2=3.03 b=4.12, loss=0.83488\n",
            "Epoch 244: W1=2.04 W2=3.03 b=4.13, loss=0.83252\n",
            "Epoch 245: W1=2.04 W2=3.03 b=4.13, loss=0.83020\n",
            "Epoch 246: W1=2.04 W2=3.03 b=4.14, loss=0.82790\n",
            "Epoch 247: W1=2.04 W2=3.03 b=4.15, loss=0.82562\n",
            "Epoch 248: W1=2.04 W2=3.03 b=4.16, loss=0.82338\n",
            "Epoch 249: W1=2.04 W2=3.03 b=4.16, loss=0.82116\n",
            "Epoch 250: W1=2.04 W2=3.03 b=4.17, loss=0.81896\n",
            "Epoch 251: W1=2.04 W2=3.03 b=4.18, loss=0.81679\n",
            "Epoch 252: W1=2.04 W2=3.03 b=4.19, loss=0.81465\n",
            "Epoch 253: W1=2.04 W2=3.03 b=4.19, loss=0.81253\n",
            "Epoch 254: W1=2.04 W2=3.03 b=4.20, loss=0.81044\n",
            "Epoch 255: W1=2.04 W2=3.03 b=4.21, loss=0.80837\n",
            "Epoch 256: W1=2.04 W2=3.03 b=4.22, loss=0.80633\n",
            "Epoch 257: W1=2.04 W2=3.03 b=4.22, loss=0.80431\n",
            "Epoch 258: W1=2.04 W2=3.03 b=4.23, loss=0.80231\n",
            "Epoch 259: W1=2.04 W2=3.03 b=4.24, loss=0.80034\n",
            "Epoch 260: W1=2.04 W2=3.03 b=4.24, loss=0.79839\n",
            "Epoch 261: W1=2.04 W2=3.03 b=4.25, loss=0.79646\n",
            "Epoch 262: W1=2.04 W2=3.03 b=4.26, loss=0.79456\n",
            "Epoch 263: W1=2.04 W2=3.03 b=4.27, loss=0.79267\n",
            "Epoch 264: W1=2.04 W2=3.03 b=4.27, loss=0.79081\n",
            "Epoch 265: W1=2.04 W2=3.03 b=4.28, loss=0.78898\n",
            "Epoch 266: W1=2.04 W2=3.03 b=4.29, loss=0.78716\n",
            "Epoch 267: W1=2.04 W2=3.03 b=4.29, loss=0.78536\n",
            "Epoch 268: W1=2.03 W2=3.03 b=4.30, loss=0.78359\n",
            "Epoch 269: W1=2.03 W2=3.03 b=4.31, loss=0.78184\n",
            "Epoch 270: W1=2.03 W2=3.03 b=4.31, loss=0.78011\n",
            "Epoch 271: W1=2.03 W2=3.03 b=4.32, loss=0.77839\n",
            "Epoch 272: W1=2.03 W2=3.03 b=4.33, loss=0.77670\n",
            "Epoch 273: W1=2.03 W2=3.03 b=4.33, loss=0.77503\n",
            "Epoch 274: W1=2.03 W2=3.03 b=4.34, loss=0.77338\n",
            "Epoch 275: W1=2.03 W2=3.03 b=4.34, loss=0.77175\n",
            "Epoch 276: W1=2.03 W2=3.03 b=4.35, loss=0.77013\n",
            "Epoch 277: W1=2.03 W2=3.03 b=4.36, loss=0.76854\n",
            "Epoch 278: W1=2.03 W2=3.03 b=4.36, loss=0.76696\n",
            "Epoch 279: W1=2.03 W2=3.03 b=4.37, loss=0.76541\n",
            "Epoch 280: W1=2.03 W2=3.03 b=4.38, loss=0.76387\n",
            "Epoch 281: W1=2.03 W2=3.03 b=4.38, loss=0.76235\n",
            "Epoch 282: W1=2.03 W2=3.03 b=4.39, loss=0.76085\n",
            "Epoch 283: W1=2.03 W2=3.03 b=4.40, loss=0.75937\n",
            "Epoch 284: W1=2.03 W2=3.03 b=4.40, loss=0.75790\n",
            "Epoch 285: W1=2.03 W2=3.03 b=4.41, loss=0.75645\n",
            "Epoch 286: W1=2.03 W2=3.03 b=4.41, loss=0.75502\n",
            "Epoch 287: W1=2.03 W2=3.03 b=4.42, loss=0.75360\n",
            "Epoch 288: W1=2.03 W2=3.03 b=4.43, loss=0.75221\n",
            "Epoch 289: W1=2.03 W2=3.03 b=4.43, loss=0.75082\n",
            "Epoch 290: W1=2.03 W2=3.03 b=4.44, loss=0.74946\n",
            "Epoch 291: W1=2.03 W2=3.03 b=4.44, loss=0.74811\n",
            "Epoch 292: W1=2.03 W2=3.03 b=4.45, loss=0.74678\n",
            "Epoch 293: W1=2.03 W2=3.02 b=4.46, loss=0.74546\n",
            "Epoch 294: W1=2.03 W2=3.02 b=4.46, loss=0.74416\n",
            "Epoch 295: W1=2.03 W2=3.02 b=4.47, loss=0.74288\n",
            "Epoch 296: W1=2.03 W2=3.02 b=4.47, loss=0.74161\n",
            "Epoch 297: W1=2.03 W2=3.02 b=4.48, loss=0.74035\n",
            "Epoch 298: W1=2.03 W2=3.02 b=4.48, loss=0.73911\n",
            "Epoch 299: W1=2.03 W2=3.02 b=4.49, loss=0.73789\n",
            "Epoch 300: W1=2.03 W2=3.02 b=4.50, loss=0.73668\n",
            "Epoch 301: W1=2.03 W2=3.02 b=4.50, loss=0.73548\n",
            "Epoch 302: W1=2.03 W2=3.02 b=4.51, loss=0.73430\n",
            "Epoch 303: W1=2.03 W2=3.02 b=4.51, loss=0.73314\n",
            "Epoch 304: W1=2.03 W2=3.02 b=4.52, loss=0.73198\n",
            "Epoch 305: W1=2.03 W2=3.02 b=4.52, loss=0.73084\n",
            "Epoch 306: W1=2.03 W2=3.02 b=4.53, loss=0.72972\n",
            "Epoch 307: W1=2.03 W2=3.02 b=4.53, loss=0.72861\n",
            "Epoch 308: W1=2.03 W2=3.02 b=4.54, loss=0.72751\n",
            "Epoch 309: W1=2.03 W2=3.02 b=4.54, loss=0.72642\n",
            "Epoch 310: W1=2.03 W2=3.02 b=4.55, loss=0.72535\n",
            "Epoch 311: W1=2.03 W2=3.02 b=4.56, loss=0.72429\n",
            "Epoch 312: W1=2.03 W2=3.02 b=4.56, loss=0.72324\n",
            "Epoch 313: W1=2.03 W2=3.02 b=4.57, loss=0.72221\n",
            "Epoch 314: W1=2.03 W2=3.02 b=4.57, loss=0.72119\n",
            "Epoch 315: W1=2.03 W2=3.02 b=4.58, loss=0.72018\n",
            "Epoch 316: W1=2.03 W2=3.02 b=4.58, loss=0.71918\n",
            "Epoch 317: W1=2.03 W2=3.02 b=4.59, loss=0.71820\n",
            "Epoch 318: W1=2.03 W2=3.02 b=4.59, loss=0.71722\n",
            "Epoch 319: W1=2.03 W2=3.02 b=4.60, loss=0.71626\n",
            "Epoch 320: W1=2.03 W2=3.02 b=4.60, loss=0.71531\n",
            "Epoch 321: W1=2.03 W2=3.02 b=4.61, loss=0.71437\n",
            "Epoch 322: W1=2.03 W2=3.02 b=4.61, loss=0.71345\n",
            "Epoch 323: W1=2.03 W2=3.02 b=4.62, loss=0.71253\n",
            "Epoch 324: W1=2.03 W2=3.02 b=4.62, loss=0.71163\n",
            "Epoch 325: W1=2.03 W2=3.02 b=4.63, loss=0.71073\n",
            "Epoch 326: W1=2.03 W2=3.02 b=4.63, loss=0.70985\n",
            "Epoch 327: W1=2.03 W2=3.02 b=4.64, loss=0.70898\n",
            "Epoch 328: W1=2.02 W2=3.02 b=4.64, loss=0.70812\n",
            "Epoch 329: W1=2.02 W2=3.02 b=4.65, loss=0.70727\n",
            "Epoch 330: W1=2.02 W2=3.02 b=4.65, loss=0.70643\n",
            "Epoch 331: W1=2.02 W2=3.02 b=4.66, loss=0.70560\n",
            "Epoch 332: W1=2.02 W2=3.02 b=4.66, loss=0.70478\n",
            "Epoch 333: W1=2.02 W2=3.02 b=4.66, loss=0.70397\n",
            "Epoch 334: W1=2.02 W2=3.02 b=4.67, loss=0.70317\n",
            "Epoch 335: W1=2.02 W2=3.02 b=4.67, loss=0.70238\n",
            "Epoch 336: W1=2.02 W2=3.02 b=4.68, loss=0.70160\n",
            "Epoch 337: W1=2.02 W2=3.02 b=4.68, loss=0.70083\n",
            "Epoch 338: W1=2.02 W2=3.02 b=4.69, loss=0.70007\n",
            "Epoch 339: W1=2.02 W2=3.02 b=4.69, loss=0.69932\n",
            "Epoch 340: W1=2.02 W2=3.02 b=4.70, loss=0.69857\n",
            "Epoch 341: W1=2.02 W2=3.02 b=4.70, loss=0.69784\n",
            "Epoch 342: W1=2.02 W2=3.02 b=4.71, loss=0.69711\n",
            "Epoch 343: W1=2.02 W2=3.02 b=4.71, loss=0.69640\n",
            "Epoch 344: W1=2.02 W2=3.02 b=4.71, loss=0.69569\n",
            "Epoch 345: W1=2.02 W2=3.02 b=4.72, loss=0.69499\n",
            "Epoch 346: W1=2.02 W2=3.02 b=4.72, loss=0.69430\n",
            "Epoch 347: W1=2.02 W2=3.02 b=4.73, loss=0.69362\n",
            "Epoch 348: W1=2.02 W2=3.02 b=4.73, loss=0.69295\n",
            "Epoch 349: W1=2.02 W2=3.02 b=4.74, loss=0.69228\n",
            "Epoch 350: W1=2.02 W2=3.02 b=4.74, loss=0.69163\n",
            "Epoch 351: W1=2.02 W2=3.02 b=4.74, loss=0.69098\n",
            "Epoch 352: W1=2.02 W2=3.02 b=4.75, loss=0.69034\n",
            "Epoch 353: W1=2.02 W2=3.02 b=4.75, loss=0.68971\n",
            "Epoch 354: W1=2.02 W2=3.02 b=4.76, loss=0.68908\n",
            "Epoch 355: W1=2.02 W2=3.02 b=4.76, loss=0.68847\n",
            "Epoch 356: W1=2.02 W2=3.02 b=4.77, loss=0.68786\n",
            "Epoch 357: W1=2.02 W2=3.02 b=4.77, loss=0.68726\n",
            "Epoch 358: W1=2.02 W2=3.02 b=4.77, loss=0.68666\n",
            "Epoch 359: W1=2.02 W2=3.02 b=4.78, loss=0.68608\n",
            "Epoch 360: W1=2.02 W2=3.02 b=4.78, loss=0.68550\n",
            "Epoch 361: W1=2.02 W2=3.02 b=4.79, loss=0.68493\n",
            "Epoch 362: W1=2.02 W2=3.02 b=4.79, loss=0.68436\n",
            "Epoch 363: W1=2.02 W2=3.02 b=4.79, loss=0.68380\n",
            "Epoch 364: W1=2.02 W2=3.02 b=4.80, loss=0.68325\n",
            "Epoch 365: W1=2.02 W2=3.02 b=4.80, loss=0.68271\n",
            "Epoch 366: W1=2.02 W2=3.02 b=4.81, loss=0.68217\n",
            "Epoch 367: W1=2.02 W2=3.02 b=4.81, loss=0.68164\n",
            "Epoch 368: W1=2.02 W2=3.02 b=4.81, loss=0.68112\n",
            "Epoch 369: W1=2.02 W2=3.01 b=4.82, loss=0.68060\n",
            "Epoch 370: W1=2.02 W2=3.01 b=4.82, loss=0.68009\n",
            "Epoch 371: W1=2.02 W2=3.01 b=4.83, loss=0.67959\n",
            "Epoch 372: W1=2.02 W2=3.01 b=4.83, loss=0.67909\n",
            "Epoch 373: W1=2.02 W2=3.01 b=4.83, loss=0.67860\n",
            "Epoch 374: W1=2.02 W2=3.01 b=4.84, loss=0.67811\n",
            "Epoch 375: W1=2.02 W2=3.01 b=4.84, loss=0.67763\n",
            "Epoch 376: W1=2.02 W2=3.01 b=4.84, loss=0.67716\n",
            "Epoch 377: W1=2.02 W2=3.01 b=4.85, loss=0.67669\n",
            "Epoch 378: W1=2.02 W2=3.01 b=4.85, loss=0.67623\n",
            "Epoch 379: W1=2.02 W2=3.01 b=4.85, loss=0.67578\n",
            "Epoch 380: W1=2.02 W2=3.01 b=4.86, loss=0.67533\n",
            "Epoch 381: W1=2.02 W2=3.01 b=4.86, loss=0.67488\n",
            "Epoch 382: W1=2.02 W2=3.01 b=4.87, loss=0.67445\n",
            "Epoch 383: W1=2.02 W2=3.01 b=4.87, loss=0.67401\n",
            "Epoch 384: W1=2.02 W2=3.01 b=4.87, loss=0.67359\n",
            "Epoch 385: W1=2.02 W2=3.01 b=4.88, loss=0.67316\n",
            "Epoch 386: W1=2.02 W2=3.01 b=4.88, loss=0.67275\n",
            "Epoch 387: W1=2.02 W2=3.01 b=4.88, loss=0.67234\n",
            "Epoch 388: W1=2.02 W2=3.01 b=4.89, loss=0.67193\n",
            "Epoch 389: W1=2.02 W2=3.01 b=4.89, loss=0.67153\n",
            "Epoch 390: W1=2.02 W2=3.01 b=4.89, loss=0.67114\n",
            "Epoch 391: W1=2.02 W2=3.01 b=4.90, loss=0.67074\n",
            "Epoch 392: W1=2.02 W2=3.01 b=4.90, loss=0.67036\n",
            "Epoch 393: W1=2.02 W2=3.01 b=4.90, loss=0.66998\n",
            "Epoch 394: W1=2.02 W2=3.01 b=4.91, loss=0.66960\n",
            "Epoch 395: W1=2.02 W2=3.01 b=4.91, loss=0.66924\n",
            "Epoch 396: W1=2.02 W2=3.01 b=4.91, loss=0.66887\n",
            "Epoch 397: W1=2.02 W2=3.01 b=4.92, loss=0.66851\n",
            "Epoch 398: W1=2.02 W2=3.01 b=4.92, loss=0.66815\n",
            "Epoch 399: W1=2.02 W2=3.01 b=4.92, loss=0.66780\n",
            "Epoch 400: W1=2.02 W2=3.01 b=4.93, loss=0.66745\n",
            "Epoch 401: W1=2.02 W2=3.01 b=4.93, loss=0.66711\n",
            "Epoch 402: W1=2.02 W2=3.01 b=4.93, loss=0.66677\n",
            "Epoch 403: W1=2.02 W2=3.01 b=4.94, loss=0.66644\n",
            "Epoch 404: W1=2.02 W2=3.01 b=4.94, loss=0.66611\n",
            "Epoch 405: W1=2.02 W2=3.01 b=4.94, loss=0.66578\n",
            "Epoch 406: W1=2.02 W2=3.01 b=4.95, loss=0.66546\n",
            "Epoch 407: W1=2.02 W2=3.01 b=4.95, loss=0.66515\n",
            "Epoch 408: W1=2.02 W2=3.01 b=4.95, loss=0.66483\n",
            "Epoch 409: W1=2.02 W2=3.01 b=4.96, loss=0.66453\n",
            "Epoch 410: W1=2.02 W2=3.01 b=4.96, loss=0.66422\n",
            "Epoch 411: W1=2.02 W2=3.01 b=4.96, loss=0.66392\n",
            "Epoch 412: W1=2.02 W2=3.01 b=4.96, loss=0.66362\n",
            "Epoch 413: W1=2.02 W2=3.01 b=4.97, loss=0.66333\n",
            "Epoch 414: W1=2.02 W2=3.01 b=4.97, loss=0.66304\n",
            "Epoch 415: W1=2.02 W2=3.01 b=4.97, loss=0.66276\n",
            "Epoch 416: W1=2.02 W2=3.01 b=4.98, loss=0.66248\n",
            "Epoch 417: W1=2.02 W2=3.01 b=4.98, loss=0.66220\n",
            "Epoch 418: W1=2.02 W2=3.01 b=4.98, loss=0.66193\n",
            "Epoch 419: W1=2.02 W2=3.01 b=4.98, loss=0.66166\n",
            "Epoch 420: W1=2.02 W2=3.01 b=4.99, loss=0.66139\n",
            "Epoch 421: W1=2.01 W2=3.01 b=4.99, loss=0.66113\n",
            "Epoch 422: W1=2.01 W2=3.01 b=4.99, loss=0.66087\n",
            "Epoch 423: W1=2.01 W2=3.01 b=5.00, loss=0.66061\n",
            "Epoch 424: W1=2.01 W2=3.01 b=5.00, loss=0.66036\n",
            "Epoch 425: W1=2.01 W2=3.01 b=5.00, loss=0.66011\n",
            "Epoch 426: W1=2.01 W2=3.01 b=5.00, loss=0.65987\n",
            "Epoch 427: W1=2.01 W2=3.01 b=5.01, loss=0.65962\n",
            "Epoch 428: W1=2.01 W2=3.01 b=5.01, loss=0.65939\n",
            "Epoch 429: W1=2.01 W2=3.01 b=5.01, loss=0.65915\n",
            "Epoch 430: W1=2.01 W2=3.01 b=5.02, loss=0.65892\n",
            "Epoch 431: W1=2.01 W2=3.01 b=5.02, loss=0.65869\n",
            "Epoch 432: W1=2.01 W2=3.01 b=5.02, loss=0.65846\n",
            "Epoch 433: W1=2.01 W2=3.01 b=5.02, loss=0.65824\n",
            "Epoch 434: W1=2.01 W2=3.01 b=5.03, loss=0.65802\n",
            "Epoch 435: W1=2.01 W2=3.01 b=5.03, loss=0.65780\n",
            "Epoch 436: W1=2.01 W2=3.01 b=5.03, loss=0.65758\n",
            "Epoch 437: W1=2.01 W2=3.01 b=5.03, loss=0.65737\n",
            "Epoch 438: W1=2.01 W2=3.01 b=5.04, loss=0.65716\n",
            "Epoch 439: W1=2.01 W2=3.01 b=5.04, loss=0.65696\n",
            "Epoch 440: W1=2.01 W2=3.01 b=5.04, loss=0.65676\n",
            "Epoch 441: W1=2.01 W2=3.01 b=5.05, loss=0.65656\n",
            "Epoch 442: W1=2.01 W2=3.01 b=5.05, loss=0.65636\n",
            "Epoch 443: W1=2.01 W2=3.01 b=5.05, loss=0.65616\n",
            "Epoch 444: W1=2.01 W2=3.01 b=5.05, loss=0.65597\n",
            "Epoch 445: W1=2.01 W2=3.01 b=5.06, loss=0.65578\n",
            "Epoch 446: W1=2.01 W2=3.01 b=5.06, loss=0.65560\n",
            "Epoch 447: W1=2.01 W2=3.01 b=5.06, loss=0.65541\n",
            "Epoch 448: W1=2.01 W2=3.01 b=5.06, loss=0.65523\n",
            "Epoch 449: W1=2.01 W2=3.01 b=5.07, loss=0.65505\n",
            "Epoch 450: W1=2.01 W2=3.01 b=5.07, loss=0.65487\n",
            "Epoch 451: W1=2.01 W2=3.01 b=5.07, loss=0.65470\n",
            "Epoch 452: W1=2.01 W2=3.01 b=5.07, loss=0.65453\n",
            "Epoch 453: W1=2.01 W2=3.01 b=5.08, loss=0.65436\n",
            "Epoch 454: W1=2.01 W2=3.01 b=5.08, loss=0.65419\n",
            "Epoch 455: W1=2.01 W2=3.01 b=5.08, loss=0.65403\n",
            "Epoch 456: W1=2.01 W2=3.01 b=5.08, loss=0.65387\n",
            "Epoch 457: W1=2.01 W2=3.01 b=5.08, loss=0.65371\n",
            "Epoch 458: W1=2.01 W2=3.01 b=5.09, loss=0.65355\n",
            "Epoch 459: W1=2.01 W2=3.01 b=5.09, loss=0.65339\n",
            "Epoch 460: W1=2.01 W2=3.01 b=5.09, loss=0.65324\n",
            "Epoch 461: W1=2.01 W2=3.01 b=5.09, loss=0.65309\n",
            "Epoch 462: W1=2.01 W2=3.01 b=5.10, loss=0.65294\n",
            "Epoch 463: W1=2.01 W2=3.01 b=5.10, loss=0.65279\n",
            "Epoch 464: W1=2.01 W2=3.01 b=5.10, loss=0.65265\n",
            "Epoch 465: W1=2.01 W2=3.01 b=5.10, loss=0.65251\n",
            "Epoch 466: W1=2.01 W2=3.01 b=5.11, loss=0.65237\n",
            "Epoch 467: W1=2.01 W2=3.01 b=5.11, loss=0.65223\n",
            "Epoch 468: W1=2.01 W2=3.01 b=5.11, loss=0.65209\n",
            "Epoch 469: W1=2.01 W2=3.01 b=5.11, loss=0.65196\n",
            "Epoch 470: W1=2.01 W2=3.01 b=5.11, loss=0.65182\n",
            "Epoch 471: W1=2.01 W2=3.01 b=5.12, loss=0.65169\n",
            "Epoch 472: W1=2.01 W2=3.01 b=5.12, loss=0.65157\n",
            "Epoch 473: W1=2.01 W2=3.01 b=5.12, loss=0.65144\n",
            "Epoch 474: W1=2.01 W2=3.01 b=5.12, loss=0.65132\n",
            "Epoch 475: W1=2.01 W2=3.01 b=5.13, loss=0.65119\n",
            "Epoch 476: W1=2.01 W2=3.01 b=5.13, loss=0.65107\n",
            "Epoch 477: W1=2.01 W2=3.01 b=5.13, loss=0.65095\n",
            "Epoch 478: W1=2.01 W2=3.01 b=5.13, loss=0.65083\n",
            "Epoch 479: W1=2.01 W2=3.01 b=5.13, loss=0.65072\n",
            "Epoch 480: W1=2.01 W2=3.01 b=5.14, loss=0.65060\n",
            "Epoch 481: W1=2.01 W2=3.01 b=5.14, loss=0.65049\n",
            "Epoch 482: W1=2.01 W2=3.01 b=5.14, loss=0.65038\n",
            "Epoch 483: W1=2.01 W2=3.01 b=5.14, loss=0.65027\n",
            "Epoch 484: W1=2.01 W2=3.01 b=5.14, loss=0.65016\n",
            "Epoch 485: W1=2.01 W2=3.01 b=5.15, loss=0.65006\n",
            "Epoch 486: W1=2.01 W2=3.01 b=5.15, loss=0.64995\n",
            "Epoch 487: W1=2.01 W2=3.01 b=5.15, loss=0.64985\n",
            "Epoch 488: W1=2.01 W2=3.01 b=5.15, loss=0.64975\n",
            "Epoch 489: W1=2.01 W2=3.01 b=5.15, loss=0.64965\n",
            "Epoch 490: W1=2.01 W2=3.01 b=5.16, loss=0.64955\n",
            "Epoch 491: W1=2.01 W2=3.01 b=5.16, loss=0.64946\n",
            "Epoch 492: W1=2.01 W2=3.01 b=5.16, loss=0.64936\n",
            "Epoch 493: W1=2.01 W2=3.01 b=5.16, loss=0.64927\n",
            "Epoch 494: W1=2.01 W2=3.01 b=5.16, loss=0.64917\n",
            "Epoch 495: W1=2.01 W2=3.01 b=5.17, loss=0.64908\n",
            "Epoch 496: W1=2.01 W2=3.01 b=5.17, loss=0.64899\n",
            "Epoch 497: W1=2.01 W2=3.01 b=5.17, loss=0.64891\n",
            "Epoch 498: W1=2.01 W2=3.01 b=5.17, loss=0.64882\n",
            "Epoch 499: W1=2.01 W2=3.01 b=5.17, loss=0.64873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDrLt9lN8dIt",
        "colab_type": "text"
      },
      "source": [
        "## **Binary Classification With Tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vsq1CELTpsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQIaoHH6TrtZ",
        "colab_type": "code",
        "outputId": "5629feba-d4f6-4032-c6ba-f86636bba094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/v7fq3tage2au7s0/Subscribers.csv -P 'drive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-21 09:46:14--  https://www.dropbox.com/s/v7fq3tage2au7s0/Subscribers.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/v7fq3tage2au7s0/Subscribers.csv [following]\n",
            "--2019-12-21 09:46:14--  https://www.dropbox.com/s/raw/v7fq3tage2au7s0/Subscribers.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucced14a27fc197428cc442a870f.dl.dropboxusercontent.com/cd/0/inline/AupV8BLrDrXRrzKaFTr3mN24flGFl6IWysmXLdPH3_zX18rRPXOMOm6nu9L-SSJCQLuOSxJ89_yVxXxrKtRkuKynyA_uN5xbYghK2DIKwEbbEg/file# [following]\n",
            "--2019-12-21 09:46:15--  https://ucced14a27fc197428cc442a870f.dl.dropboxusercontent.com/cd/0/inline/AupV8BLrDrXRrzKaFTr3mN24flGFl6IWysmXLdPH3_zX18rRPXOMOm6nu9L-SSJCQLuOSxJ89_yVxXxrKtRkuKynyA_uN5xbYghK2DIKwEbbEg/file\n",
            "Resolving ucced14a27fc197428cc442a870f.dl.dropboxusercontent.com (ucced14a27fc197428cc442a870f.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to ucced14a27fc197428cc442a870f.dl.dropboxusercontent.com (ucced14a27fc197428cc442a870f.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131375993 (125M) [text/plain]\n",
            "Saving to: ‘drive/My Drive/Colab Notebooks/Subscribers.csv’\n",
            "\n",
            "Subscribers.csv     100%[===================>] 125.29M  56.5MB/s    in 2.2s    \n",
            "\n",
            "2019-12-21 09:46:17 (56.5 MB/s) - ‘drive/My Drive/Colab Notebooks/Subscribers.csv’ saved [131375993/131375993]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdP8lTvtTpse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"drive/My Drive/Colab Notebooks/Subscribers.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-xI249lTpsk",
        "colab_type": "code",
        "outputId": "581783f9-79cd-4be1-d419-955d430fa4e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300000, 51)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIy5u9-_CM_B",
        "colab_type": "code",
        "outputId": "419125a2-e7a3-4b81-8cc8-63777f103841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wINyZ0WxTpsp",
        "colab_type": "code",
        "outputId": "5f60375c-592f-410b-e8df-8fc962f87f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>V46</th>\n",
              "      <th>V47</th>\n",
              "      <th>V48</th>\n",
              "      <th>V49</th>\n",
              "      <th>V50</th>\n",
              "      <th>Subscribers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.211875</td>\n",
              "      <td>743952.92</td>\n",
              "      <td>743952.92</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>743952.92</td>\n",
              "      <td>200000.000</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>-0.069396</td>\n",
              "      <td>943952.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>46898.57</td>\n",
              "      <td>1520.75</td>\n",
              "      <td>-0.022604</td>\n",
              "      <td>853402.02</td>\n",
              "      <td>841385.39</td>\n",
              "      <td>841385.39</td>\n",
              "      <td>1014344.86</td>\n",
              "      <td>943952.92</td>\n",
              "      <td>1014344.86</td>\n",
              "      <td>9.007502e+05</td>\n",
              "      <td>1947</td>\n",
              "      <td>943952.92</td>\n",
              "      <td>28.0</td>\n",
              "      <td>9.007502e+05</td>\n",
              "      <td>-0.151781</td>\n",
              "      <td>0.454159</td>\n",
              "      <td>1223508.20</td>\n",
              "      <td>943952.92</td>\n",
              "      <td>1223508.20</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1057802.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1037</td>\n",
              "      <td>1037802.92</td>\n",
              "      <td>1037802.92</td>\n",
              "      <td>1007802.92</td>\n",
              "      <td>1.034232e+06</td>\n",
              "      <td>59</td>\n",
              "      <td>9.007502e+05</td>\n",
              "      <td>1.034232e+06</td>\n",
              "      <td>1</td>\n",
              "      <td>1.034232e+06</td>\n",
              "      <td>1966.57</td>\n",
              "      <td>1990.82</td>\n",
              "      <td>1752.89</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>1826.046667</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2557.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.241488</td>\n",
              "      <td>11295310.87</td>\n",
              "      <td>8034290.99</td>\n",
              "      <td>32000.0</td>\n",
              "      <td>8034290.99</td>\n",
              "      <td>18000.000</td>\n",
              "      <td>14000.0</td>\n",
              "      <td>0.167411</td>\n",
              "      <td>7508345.76</td>\n",
              "      <td>1160925.13</td>\n",
              "      <td>1140925.13</td>\n",
              "      <td>18340.86</td>\n",
              "      <td>-0.071992</td>\n",
              "      <td>8344246.15</td>\n",
              "      <td>8684104.76</td>\n",
              "      <td>8684104.76</td>\n",
              "      <td>5543465.03</td>\n",
              "      <td>6471503.11</td>\n",
              "      <td>5543465.03</td>\n",
              "      <td>6.683086e+06</td>\n",
              "      <td>3082</td>\n",
              "      <td>6471503.11</td>\n",
              "      <td>16.0</td>\n",
              "      <td>6.683086e+06</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.302890</td>\n",
              "      <td>6053779.08</td>\n",
              "      <td>4562383.16</td>\n",
              "      <td>6053779.08</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5681015.79</td>\n",
              "      <td>1135925.13</td>\n",
              "      <td>60</td>\n",
              "      <td>5973512.08</td>\n",
              "      <td>5973512.08</td>\n",
              "      <td>7467485.79</td>\n",
              "      <td>6.903799e+06</td>\n",
              "      <td>37</td>\n",
              "      <td>5.272982e+07</td>\n",
              "      <td>6.903799e+06</td>\n",
              "      <td>2</td>\n",
              "      <td>5.665658e+07</td>\n",
              "      <td>49957.65</td>\n",
              "      <td>11104.54</td>\n",
              "      <td>17711.99</td>\n",
              "      <td>38000.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26467.683330</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12807.07</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.459032</td>\n",
              "      <td>20363.68</td>\n",
              "      <td>317922.94</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>317922.94</td>\n",
              "      <td>1650000.000</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>46.068404</td>\n",
              "      <td>1655168.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>46898.57</td>\n",
              "      <td>482.92</td>\n",
              "      <td>0.048818</td>\n",
              "      <td>28961.32</td>\n",
              "      <td>28240.31</td>\n",
              "      <td>28240.31</td>\n",
              "      <td>4629.43</td>\n",
              "      <td>217899.88</td>\n",
              "      <td>4629.43</td>\n",
              "      <td>1.801508e+05</td>\n",
              "      <td>572</td>\n",
              "      <td>217899.88</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.801508e+05</td>\n",
              "      <td>-0.906061</td>\n",
              "      <td>0.663840</td>\n",
              "      <td>46987.35</td>\n",
              "      <td>4888.24</td>\n",
              "      <td>46987.35</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4362.67</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3638</td>\n",
              "      <td>4413.95</td>\n",
              "      <td>4413.95</td>\n",
              "      <td>4429.49</td>\n",
              "      <td>2.654720e+04</td>\n",
              "      <td>37</td>\n",
              "      <td>1.801508e+05</td>\n",
              "      <td>2.654720e+04</td>\n",
              "      <td>4</td>\n",
              "      <td>2.654720e+04</td>\n",
              "      <td>453.96</td>\n",
              "      <td>9.64</td>\n",
              "      <td>58.83</td>\n",
              "      <td>45072.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>315.506667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>45554.885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>0.00</td>\n",
              "      <td>46898.57</td>\n",
              "      <td>2045.09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>839849.98</td>\n",
              "      <td>839849.98</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>8.561209e+05</td>\n",
              "      <td>773</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>146.0</td>\n",
              "      <td>8.561209e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019374</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>12.0</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1879</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>8.506973e+05</td>\n",
              "      <td>56</td>\n",
              "      <td>8.561209e+05</td>\n",
              "      <td>8.506973e+05</td>\n",
              "      <td>0</td>\n",
              "      <td>8.506973e+05</td>\n",
              "      <td>2045.09</td>\n",
              "      <td>2045.09</td>\n",
              "      <td>2011.19</td>\n",
              "      <td>45072.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2045.090000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2029.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.270783</td>\n",
              "      <td>194485.64</td>\n",
              "      <td>412330.33</td>\n",
              "      <td>835000.0</td>\n",
              "      <td>412330.33</td>\n",
              "      <td>835000.000</td>\n",
              "      <td>835000.0</td>\n",
              "      <td>-0.272225</td>\n",
              "      <td>2241.64</td>\n",
              "      <td>78625.00</td>\n",
              "      <td>78625.00</td>\n",
              "      <td>713.13</td>\n",
              "      <td>-0.150621</td>\n",
              "      <td>59396.64</td>\n",
              "      <td>65139.84</td>\n",
              "      <td>65139.84</td>\n",
              "      <td>61112.77</td>\n",
              "      <td>44476.32</td>\n",
              "      <td>61112.77</td>\n",
              "      <td>1.726398e+05</td>\n",
              "      <td>1627</td>\n",
              "      <td>44476.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.726398e+05</td>\n",
              "      <td>1.391400</td>\n",
              "      <td>-0.538117</td>\n",
              "      <td>30086.96</td>\n",
              "      <td>61066.64</td>\n",
              "      <td>30086.96</td>\n",
              "      <td>3.0</td>\n",
              "      <td>24196.64</td>\n",
              "      <td>78625.00</td>\n",
              "      <td>143</td>\n",
              "      <td>71949.97</td>\n",
              "      <td>71949.97</td>\n",
              "      <td>72196.64</td>\n",
              "      <td>5.572559e+04</td>\n",
              "      <td>36</td>\n",
              "      <td>1.726398e+05</td>\n",
              "      <td>5.572559e+04</td>\n",
              "      <td>5</td>\n",
              "      <td>5.572559e+04</td>\n",
              "      <td>70.01</td>\n",
              "      <td>100.60</td>\n",
              "      <td>89.59</td>\n",
              "      <td>31080.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>294.580000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1           V2          V3  ...   V49       V50  Subscribers\n",
              "0 -0.211875    743952.92   743952.92  ...  28.0   2557.22            0\n",
              "1  0.241488  11295310.87  8034290.99  ...  19.0  12807.07            0\n",
              "2  0.459032     20363.68   317922.94  ...   0.0     32.12            1\n",
              "3  0.000000    856120.91   856120.91  ...  19.0   2029.79            0\n",
              "4  8.270783    194485.64   412330.33  ...   0.0     26.95            0\n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJNrcx4dTpst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=pd.get_dummies(data['Subscribers'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdDKJYX6Tpsw",
        "colab_type": "code",
        "outputId": "1e25b439-fa2e-452b-ec46-65108aeb46d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299997</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299999</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0  1\n",
              "0       1  0\n",
              "1       1  0\n",
              "2       0  1\n",
              "3       1  0\n",
              "4       1  0\n",
              "...    .. ..\n",
              "299995  1  0\n",
              "299996  1  0\n",
              "299997  1  0\n",
              "299998  1  0\n",
              "299999  0  1\n",
              "\n",
              "[300000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb_fG53hTps0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data.drop(['Subscribers'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0BCba52Tps4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,\n",
        "                                               random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRRFSfSITps8",
        "colab_type": "code",
        "outputId": "af468f34-ad3b-4815-ea46-42b27dc000cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>V46</th>\n",
              "      <th>V47</th>\n",
              "      <th>V48</th>\n",
              "      <th>V49</th>\n",
              "      <th>V50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18736</th>\n",
              "      <td>-0.629091</td>\n",
              "      <td>228317.55</td>\n",
              "      <td>117202.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>117202.89</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.301283</td>\n",
              "      <td>23762.55</td>\n",
              "      <td>121000.00</td>\n",
              "      <td>121000.00</td>\n",
              "      <td>271.57</td>\n",
              "      <td>13.459181</td>\n",
              "      <td>32577.05</td>\n",
              "      <td>32044.55</td>\n",
              "      <td>32044.55</td>\n",
              "      <td>452240.53</td>\n",
              "      <td>315988.36</td>\n",
              "      <td>452240.53</td>\n",
              "      <td>295143.9267</td>\n",
              "      <td>1264</td>\n",
              "      <td>315988.36</td>\n",
              "      <td>10.0</td>\n",
              "      <td>295143.9267</td>\n",
              "      <td>-0.030303</td>\n",
              "      <td>0.006551</td>\n",
              "      <td>32254.47</td>\n",
              "      <td>835762.55</td>\n",
              "      <td>32254.47</td>\n",
              "      <td>10.0</td>\n",
              "      <td>31577.05</td>\n",
              "      <td>121000.0</td>\n",
              "      <td>1242</td>\n",
              "      <td>31277.05</td>\n",
              "      <td>31277.05</td>\n",
              "      <td>30577.05</td>\n",
              "      <td>31858.6900</td>\n",
              "      <td>36</td>\n",
              "      <td>3.551439e+05</td>\n",
              "      <td>31858.6900</td>\n",
              "      <td>0</td>\n",
              "      <td>9.185869e+04</td>\n",
              "      <td>660.10</td>\n",
              "      <td>1059.93</td>\n",
              "      <td>97.01</td>\n",
              "      <td>383700.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>663.866667</td>\n",
              "      <td>10.0</td>\n",
              "      <td>98.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147527</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>0.00</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>45554.885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>0.00</td>\n",
              "      <td>46898.57</td>\n",
              "      <td>449.40</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>176173.31</td>\n",
              "      <td>176173.31</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>179586.6100</td>\n",
              "      <td>2859</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>368.0</td>\n",
              "      <td>179586.6100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019375</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>12.0</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>179586.61</td>\n",
              "      <td>178448.8433</td>\n",
              "      <td>52</td>\n",
              "      <td>2.699007e+05</td>\n",
              "      <td>178448.8433</td>\n",
              "      <td>0</td>\n",
              "      <td>2.687630e+05</td>\n",
              "      <td>449.40</td>\n",
              "      <td>449.40</td>\n",
              "      <td>442.29</td>\n",
              "      <td>45072.00</td>\n",
              "      <td>30.0</td>\n",
              "      <td>449.400000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>449.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1729</th>\n",
              "      <td>-0.108635</td>\n",
              "      <td>107500.00</td>\n",
              "      <td>106724.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>106724.14</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.129023</td>\n",
              "      <td>162916.00</td>\n",
              "      <td>48030.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1381.95</td>\n",
              "      <td>-0.067136</td>\n",
              "      <td>114114.00</td>\n",
              "      <td>110803.80</td>\n",
              "      <td>110803.80</td>\n",
              "      <td>106048.39</td>\n",
              "      <td>119731.10</td>\n",
              "      <td>106048.39</td>\n",
              "      <td>110834.5433</td>\n",
              "      <td>3219</td>\n",
              "      <td>119731.10</td>\n",
              "      <td>32.0</td>\n",
              "      <td>110834.5433</td>\n",
              "      <td>-0.061502</td>\n",
              "      <td>0.093195</td>\n",
              "      <td>121130.13</td>\n",
              "      <td>107500.00</td>\n",
              "      <td>121130.13</td>\n",
              "      <td>22.0</td>\n",
              "      <td>121614.00</td>\n",
              "      <td>48030.0</td>\n",
              "      <td>285</td>\n",
              "      <td>113680.40</td>\n",
              "      <td>113680.40</td>\n",
              "      <td>100000.00</td>\n",
              "      <td>115204.7767</td>\n",
              "      <td>41</td>\n",
              "      <td>1.474183e+06</td>\n",
              "      <td>115204.7767</td>\n",
              "      <td>0</td>\n",
              "      <td>1.335116e+06</td>\n",
              "      <td>1312.09</td>\n",
              "      <td>1289.69</td>\n",
              "      <td>1226.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1327.910000</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1254.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189132</th>\n",
              "      <td>0.344743</td>\n",
              "      <td>581827.88</td>\n",
              "      <td>581810.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>581810.16</td>\n",
              "      <td>45554.885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.015048</td>\n",
              "      <td>455474.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>46898.57</td>\n",
              "      <td>1138.56</td>\n",
              "      <td>0.030115</td>\n",
              "      <td>492814.24</td>\n",
              "      <td>470079.07</td>\n",
              "      <td>470079.07</td>\n",
              "      <td>439265.30</td>\n",
              "      <td>432655.25</td>\n",
              "      <td>439265.30</td>\n",
              "      <td>484576.9033</td>\n",
              "      <td>923</td>\n",
              "      <td>432655.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>484576.9033</td>\n",
              "      <td>-0.089513</td>\n",
              "      <td>-0.003685</td>\n",
              "      <td>468346.83</td>\n",
              "      <td>439274.60</td>\n",
              "      <td>468346.83</td>\n",
              "      <td>129.0</td>\n",
              "      <td>432930.42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>946</td>\n",
              "      <td>426423.75</td>\n",
              "      <td>426423.75</td>\n",
              "      <td>449130.42</td>\n",
              "      <td>454949.8833</td>\n",
              "      <td>64</td>\n",
              "      <td>4.845769e+05</td>\n",
              "      <td>454949.8833</td>\n",
              "      <td>0</td>\n",
              "      <td>5.749499e+05</td>\n",
              "      <td>988.01</td>\n",
              "      <td>1006.81</td>\n",
              "      <td>1032.64</td>\n",
              "      <td>45072.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1044.460000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1040.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280431</th>\n",
              "      <td>0.531380</td>\n",
              "      <td>250918.54</td>\n",
              "      <td>149340.88</td>\n",
              "      <td>141979.55</td>\n",
              "      <td>149340.88</td>\n",
              "      <td>138979.550</td>\n",
              "      <td>74992.0</td>\n",
              "      <td>-0.109655</td>\n",
              "      <td>175804.51</td>\n",
              "      <td>73945.61</td>\n",
              "      <td>73945.61</td>\n",
              "      <td>389.11</td>\n",
              "      <td>0.547455</td>\n",
              "      <td>441880.14</td>\n",
              "      <td>137514.80</td>\n",
              "      <td>137514.80</td>\n",
              "      <td>109531.08</td>\n",
              "      <td>97520.43</td>\n",
              "      <td>109531.08</td>\n",
              "      <td>118797.4633</td>\n",
              "      <td>2083</td>\n",
              "      <td>97520.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>118797.4633</td>\n",
              "      <td>-0.432819</td>\n",
              "      <td>-0.092496</td>\n",
              "      <td>124795.21</td>\n",
              "      <td>94000.00</td>\n",
              "      <td>124795.21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>116976.22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>223</td>\n",
              "      <td>70781.43</td>\n",
              "      <td>70781.43</td>\n",
              "      <td>130661.97</td>\n",
              "      <td>111030.4800</td>\n",
              "      <td>40</td>\n",
              "      <td>7.833790e+05</td>\n",
              "      <td>111030.4800</td>\n",
              "      <td>2</td>\n",
              "      <td>2.777495e+05</td>\n",
              "      <td>2084.53</td>\n",
              "      <td>417.05</td>\n",
              "      <td>230.61</td>\n",
              "      <td>108869.51</td>\n",
              "      <td>4.0</td>\n",
              "      <td>963.563333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>178.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33867</th>\n",
              "      <td>0.013980</td>\n",
              "      <td>190788.69</td>\n",
              "      <td>282149.59</td>\n",
              "      <td>300000.00</td>\n",
              "      <td>282149.59</td>\n",
              "      <td>300000.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.788668</td>\n",
              "      <td>252215.69</td>\n",
              "      <td>404485.80</td>\n",
              "      <td>404485.80</td>\n",
              "      <td>1557.48</td>\n",
              "      <td>-0.283188</td>\n",
              "      <td>241983.94</td>\n",
              "      <td>260747.07</td>\n",
              "      <td>260747.07</td>\n",
              "      <td>155567.97</td>\n",
              "      <td>278259.42</td>\n",
              "      <td>155567.97</td>\n",
              "      <td>238658.9933</td>\n",
              "      <td>2623</td>\n",
              "      <td>278259.42</td>\n",
              "      <td>14.0</td>\n",
              "      <td>238658.9933</td>\n",
              "      <td>-0.050595</td>\n",
              "      <td>-0.123315</td>\n",
              "      <td>228593.17</td>\n",
              "      <td>268497.94</td>\n",
              "      <td>228593.17</td>\n",
              "      <td>14.0</td>\n",
              "      <td>222277.94</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>106</td>\n",
              "      <td>217027.57</td>\n",
              "      <td>217027.57</td>\n",
              "      <td>146326.94</td>\n",
              "      <td>235455.9367</td>\n",
              "      <td>37</td>\n",
              "      <td>7.386590e+05</td>\n",
              "      <td>235455.9367</td>\n",
              "      <td>0</td>\n",
              "      <td>7.354559e+05</td>\n",
              "      <td>995.99</td>\n",
              "      <td>1567.45</td>\n",
              "      <td>1086.62</td>\n",
              "      <td>113334.00</td>\n",
              "      <td>135.0</td>\n",
              "      <td>1373.640000</td>\n",
              "      <td>53.0</td>\n",
              "      <td>942.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84434</th>\n",
              "      <td>0.036289</td>\n",
              "      <td>153162.20</td>\n",
              "      <td>142944.78</td>\n",
              "      <td>23798.80</td>\n",
              "      <td>142944.78</td>\n",
              "      <td>23798.800</td>\n",
              "      <td>6460.0</td>\n",
              "      <td>0.035871</td>\n",
              "      <td>154403.45</td>\n",
              "      <td>10376.19</td>\n",
              "      <td>10376.19</td>\n",
              "      <td>1183.30</td>\n",
              "      <td>-0.033963</td>\n",
              "      <td>71571.94</td>\n",
              "      <td>89390.34</td>\n",
              "      <td>89390.34</td>\n",
              "      <td>133162.34</td>\n",
              "      <td>137939.07</td>\n",
              "      <td>133162.34</td>\n",
              "      <td>138015.3967</td>\n",
              "      <td>4000</td>\n",
              "      <td>137939.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>138015.3967</td>\n",
              "      <td>0.249735</td>\n",
              "      <td>0.233898</td>\n",
              "      <td>110298.52</td>\n",
              "      <td>136996.64</td>\n",
              "      <td>110298.52</td>\n",
              "      <td>6.0</td>\n",
              "      <td>141649.28</td>\n",
              "      <td>4523.0</td>\n",
              "      <td>131</td>\n",
              "      <td>137843.91</td>\n",
              "      <td>137843.91</td>\n",
              "      <td>119564.83</td>\n",
              "      <td>112510.9233</td>\n",
              "      <td>50</td>\n",
              "      <td>3.253254e+05</td>\n",
              "      <td>112510.9233</td>\n",
              "      <td>2</td>\n",
              "      <td>2.966229e+05</td>\n",
              "      <td>397.49</td>\n",
              "      <td>531.77</td>\n",
              "      <td>383.30</td>\n",
              "      <td>8885.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>704.186667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95816</th>\n",
              "      <td>-0.469078</td>\n",
              "      <td>566118.15</td>\n",
              "      <td>76905.23</td>\n",
              "      <td>85000.00</td>\n",
              "      <td>76905.23</td>\n",
              "      <td>85000.000</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>0.266498</td>\n",
              "      <td>474668.90</td>\n",
              "      <td>71021.00</td>\n",
              "      <td>71021.00</td>\n",
              "      <td>23960.87</td>\n",
              "      <td>-0.006639</td>\n",
              "      <td>739680.38</td>\n",
              "      <td>221163.31</td>\n",
              "      <td>221163.31</td>\n",
              "      <td>114372.22</td>\n",
              "      <td>144852.19</td>\n",
              "      <td>114372.22</td>\n",
              "      <td>112043.2133</td>\n",
              "      <td>2692</td>\n",
              "      <td>144852.19</td>\n",
              "      <td>7.0</td>\n",
              "      <td>112043.2133</td>\n",
              "      <td>-0.382688</td>\n",
              "      <td>-0.156674</td>\n",
              "      <td>186512.73</td>\n",
              "      <td>478061.48</td>\n",
              "      <td>186512.73</td>\n",
              "      <td>7.0</td>\n",
              "      <td>459628.97</td>\n",
              "      <td>16906.0</td>\n",
              "      <td>539</td>\n",
              "      <td>115136.62</td>\n",
              "      <td>115136.62</td>\n",
              "      <td>324215.28</td>\n",
              "      <td>174270.8867</td>\n",
              "      <td>47</td>\n",
              "      <td>2.850680e+07</td>\n",
              "      <td>174270.8867</td>\n",
              "      <td>1</td>\n",
              "      <td>2.735930e+07</td>\n",
              "      <td>23151.09</td>\n",
              "      <td>22652.13</td>\n",
              "      <td>22798.06</td>\n",
              "      <td>323773.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23254.696670</td>\n",
              "      <td>7.0</td>\n",
              "      <td>22931.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203245</th>\n",
              "      <td>0.036412</td>\n",
              "      <td>286019.00</td>\n",
              "      <td>282964.79</td>\n",
              "      <td>1000.00</td>\n",
              "      <td>282964.79</td>\n",
              "      <td>1000.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037845</td>\n",
              "      <td>277007.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>662.40</td>\n",
              "      <td>0.033041</td>\n",
              "      <td>220003.00</td>\n",
              "      <td>209716.97</td>\n",
              "      <td>209716.97</td>\n",
              "      <td>263067.55</td>\n",
              "      <td>273023.39</td>\n",
              "      <td>263067.55</td>\n",
              "      <td>273018.5767</td>\n",
              "      <td>606</td>\n",
              "      <td>273023.39</td>\n",
              "      <td>129.0</td>\n",
              "      <td>273018.5767</td>\n",
              "      <td>0.090696</td>\n",
              "      <td>0.113300</td>\n",
              "      <td>233477.97</td>\n",
              "      <td>270083.00</td>\n",
              "      <td>233477.97</td>\n",
              "      <td>3.0</td>\n",
              "      <td>244999.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1847</td>\n",
              "      <td>254653.47</td>\n",
              "      <td>254653.47</td>\n",
              "      <td>259456.00</td>\n",
              "      <td>232616.1367</td>\n",
              "      <td>29</td>\n",
              "      <td>3.604876e+05</td>\n",
              "      <td>232616.1367</td>\n",
              "      <td>0</td>\n",
              "      <td>3.200851e+05</td>\n",
              "      <td>641.69</td>\n",
              "      <td>620.95</td>\n",
              "      <td>505.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>129.0</td>\n",
              "      <td>641.680000</td>\n",
              "      <td>129.0</td>\n",
              "      <td>546.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100879</th>\n",
              "      <td>0.035484</td>\n",
              "      <td>329115.32</td>\n",
              "      <td>329115.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>329115.32</td>\n",
              "      <td>45554.885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.060706</td>\n",
              "      <td>313834.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>46898.57</td>\n",
              "      <td>806.08</td>\n",
              "      <td>-0.059702</td>\n",
              "      <td>356156.71</td>\n",
              "      <td>349229.58</td>\n",
              "      <td>349229.58</td>\n",
              "      <td>338378.93</td>\n",
              "      <td>317837.25</td>\n",
              "      <td>338378.93</td>\n",
              "      <td>328443.8333</td>\n",
              "      <td>4561</td>\n",
              "      <td>317837.25</td>\n",
              "      <td>340.0</td>\n",
              "      <td>328443.8333</td>\n",
              "      <td>0.005025</td>\n",
              "      <td>0.025298</td>\n",
              "      <td>358064.54</td>\n",
              "      <td>336766.03</td>\n",
              "      <td>358064.54</td>\n",
              "      <td>340.0</td>\n",
              "      <td>358084.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>231</td>\n",
              "      <td>359863.66</td>\n",
              "      <td>359863.66</td>\n",
              "      <td>359925.03</td>\n",
              "      <td>355719.2600</td>\n",
              "      <td>67</td>\n",
              "      <td>3.284438e+05</td>\n",
              "      <td>355719.2600</td>\n",
              "      <td>0</td>\n",
              "      <td>3.557193e+05</td>\n",
              "      <td>782.58</td>\n",
              "      <td>825.37</td>\n",
              "      <td>847.99</td>\n",
              "      <td>45072.00</td>\n",
              "      <td>30.0</td>\n",
              "      <td>804.676667</td>\n",
              "      <td>342.0</td>\n",
              "      <td>866.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>240000 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              V1         V2         V3  ...           V48    V49       V50\n",
              "18736  -0.629091  228317.55  117202.89  ...    663.866667   10.0     98.30\n",
              "147527  0.000000  179586.61  179586.61  ...    449.400000   19.0    449.40\n",
              "1729   -0.108635  107500.00  106724.14  ...   1327.910000   32.0   1254.93\n",
              "189132  0.344743  581827.88  581810.16  ...   1044.460000    0.0   1040.95\n",
              "280431  0.531380  250918.54  149340.88  ...    963.563333    0.0    178.50\n",
              "...          ...        ...        ...  ...           ...    ...       ...\n",
              "33867   0.013980  190788.69  282149.59  ...   1373.640000   53.0    942.90\n",
              "84434   0.036289  153162.20  142944.78  ...    704.186667    0.0    206.02\n",
              "95816  -0.469078  566118.15   76905.23  ...  23254.696670    7.0  22931.90\n",
              "203245  0.036412  286019.00  282964.79  ...    641.680000  129.0    546.92\n",
              "100879  0.035484  329115.32  329115.32  ...    804.676667  342.0    866.38\n",
              "\n",
              "[240000 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q12-VsHTptA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.reset_index(drop=True,inplace=True)\n",
        "y_train.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn_LbBezTptF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st=StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knvqIUQ1TptJ",
        "colab_type": "code",
        "outputId": "e0ac687b-1ef1-409d-e903-1cdc0e4d695a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "st.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFURSnkeTptN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=pd.DataFrame(st.transform(x_train))\n",
        "x_test=pd.DataFrame(st.transform(x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYYroZ1yTptR",
        "colab_type": "code",
        "outputId": "d90dff22-cc4a-483c-c72e-b33b2d578eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auryU2xcTptV",
        "colab_type": "text"
      },
      "source": [
        "# simple logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eHdheTFTptW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = tf.Variable(tf.random.normal(shape=(50, 2), dtype=tf.float64))\n",
        "biases  = tf.Variable(tf.random.normal(shape=(2,), dtype=tf.float64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7cetlBoTptZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression(x):\n",
        "    lr = tf.add(tf.matmul(x, weights), biases)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32)\n",
        "    preds = tf.cast(tf.argmax(y_pred, axis=1), dtype=tf.int32)\n",
        "    preds = tf.equal(y_true, preds)\n",
        "    return tf.reduce_mean(tf.cast(preds, dtype=tf.float32))\n",
        "\n",
        "def roc_auc(y_true,x):\n",
        "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32).numpy()\n",
        "    y_pred=tf.nn.softmax(logistic_regression(x))[:,1]\n",
        "    return(roc_auc_score(y_true,y_pred))\n",
        "\n",
        "def grad(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = logistic_regression(x)\n",
        "        loss_val = cross_entropy(y, y_pred)\n",
        "    return tape.gradient(loss_val, [weights, biases]),loss_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plMelDEYTptc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=2000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScsUqHhdTptt",
        "colab_type": "code",
        "outputId": "f337a771-3fa7-45a8-bacc-e6a6b662e2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "learning_rate=0.01\n",
        "loss_list=[]\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "    #rand_ind=np.random.choice(range(x_train.shape[0]),100)\n",
        "    #outputs=y_train.iloc[rand_ind,:].values\n",
        "    #inputs=x_train.iloc[rand_ind,:].values\n",
        "\n",
        "  for j in range(0,np.int(x_train.shape[0]/100),100):\n",
        "    outputs=y_train.iloc[j:j+100,:].values\n",
        "    inputs=x_train.iloc[j:j+100].values\n",
        "    \n",
        "    wts,loss=grad(inputs,tf.cast(outputs,'float32'))\n",
        "    \n",
        "    weights.assign_sub(learning_rate*wts[0])\n",
        "    biases.assign_sub(learning_rate*wts[1])\n",
        "  loss_list.append(loss.numpy())\n",
        "  if epoch%50==0:\n",
        "    print(accuracy(y_test.values,logistic_regression(x_test.values)).numpy(),roc_auc(y_test.values,x_test.values))\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7668167 0.6276370960006901\n",
            "0.8124 0.6312980315095917\n",
            "0.8174 0.6422347163848918\n",
            "0.81965 0.6477188252511283\n",
            "0.82095 0.6519828707353742\n",
            "0.82265 0.6559096780806616\n",
            "0.82376665 0.6597513352820331\n",
            "0.8246833 0.663492459338098\n",
            "0.8251167 0.6670485858779112\n",
            "0.8254167 0.6703669699726549\n",
            "0.82575 0.6733810213084395\n",
            "0.8262333 0.6761831482815674\n",
            "0.8268167 0.6787328121359761\n",
            "0.82708335 0.6811670502397434\n",
            "0.82733333 0.6835251206532553\n",
            "0.8277 0.6857875052227179\n",
            "0.82806665 0.6879837234461965\n",
            "0.8284 0.6901353683803204\n",
            "0.8287 0.6921898172068432\n",
            "0.82883334 0.6941452802732251\n",
            "0.82895 0.6960538177121975\n",
            "0.82915 0.6978228296580813\n",
            "0.8293167 0.6994573255749734\n",
            "0.82946664 0.7009715923997724\n",
            "0.8296667 0.7023795683215839\n",
            "0.8297833 0.703652577870615\n",
            "0.8298333 0.7048739805613569\n",
            "0.82981664 0.7060279801702435\n",
            "0.82986665 0.7070918826917303\n",
            "0.82996666 0.70805712280187\n",
            "0.8301333 0.7089957525762067\n",
            "0.8302 0.709909198266219\n",
            "0.83021665 0.7107891290002574\n",
            "0.8302 0.7116323581808406\n",
            "0.83026665 0.7124315748038148\n",
            "0.83035 0.7131940117225679\n",
            "0.8304 0.7139226328048984\n",
            "0.8304667 0.7146150407760609\n",
            "0.8305333 0.7152796876413918\n",
            "0.83061665 0.7159224522922593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcIQrx3PZT_z",
        "colab_type": "code",
        "outputId": "257cc2e0-378e-48cd-b604-1e115bfc34aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(loss_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsg4IdTDZ0-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wts=grad(inputs,tf.cast(outputs,'float32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvtR7j6QfQmP",
        "colab_type": "code",
        "outputId": "c34deeee-c6ec-4f74-c9ef-a9e75e3ba220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wts[0][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([-0.04448503,  0.04448503])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rmOn4gRTptz",
        "colab_type": "text"
      },
      "source": [
        "# classfier with a hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jjTaFPfc7nT",
        "colab_type": "code",
        "outputId": "6915a70e-0eb7-4ff8-eefc-3d3ad6eba9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "db"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-882dbe744a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsmTbzAGTpt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_h = tf.Variable(tf.random.truncated_normal(shape=(50, 20), dtype=tf.float64))\n",
        "biases_h  = tf.Variable(tf.random.truncated_normal(shape=(20,), dtype=tf.float64))\n",
        "\n",
        "weights_o = tf.Variable(tf.random.truncated_normal(shape=(20, 2), dtype=tf.float64))\n",
        "biases_o  = tf.Variable(tf.random.truncated_normal(shape=(2,), dtype=tf.float64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV_Bm0DGTpt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression(x):\n",
        "    h_o = tf.add(tf.matmul(x, weights_h), biases_h)\n",
        "    h_o=tf.nn.relu(h_o)\n",
        "    lr=tf.add(tf.matmul(h_o, weights_o), biases_o)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32)\n",
        "    preds = tf.cast(tf.argmax(y_pred, axis=1), dtype=tf.int32)\n",
        "    preds = tf.equal(y_true, preds)\n",
        "    return tf.reduce_mean(tf.cast(preds, dtype=tf.float32))\n",
        "\n",
        "def roc_auc(y_true,x):\n",
        "    y_true = tf.cast(tf.argmax(y_true, axis=1), dtype=tf.int32).numpy()\n",
        "    y_pred=tf.nn.softmax(logistic_regression(x))[:,1]\n",
        "    return(roc_auc_score(y_true,y_pred))\n",
        "\n",
        "def grad(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = logistic_regression(x)\n",
        "        loss_val = cross_entropy(y, y_pred)\n",
        "    return tape.gradient(loss_val, [weights_h, biases_h,weights_o, biases_o])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZR8EqyyTpt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=2000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xUCzOsUTpt_",
        "colab_type": "code",
        "outputId": "19a4640e-5da3-4269-f995-eda12e7d03c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "learning_rate=0.01\n",
        "for epoch in range(epochs):\n",
        "    #rand_ind=np.random.choice(range(x_train.shape[0]),100)\n",
        "    #outputs=y_train.iloc[rand_ind,:].values\n",
        "    #inputs=x_train.iloc[rand_ind,:].values\n",
        "    for j in range(0,np.int(x_train.shape[0]/100),100):\n",
        "      outputs=y_train.iloc[j:j+100,:].values\n",
        "      inputs=x_train.iloc[j:j+100].values\n",
        "    \n",
        "      dw_h,db_h,dw_o,db_o=grad(inputs,tf.cast(outputs,'float32'))\n",
        "    \n",
        "      weights_h.assign_sub(learning_rate*dw_h)\n",
        "      biases_h.assign_sub(learning_rate*db_h)\n",
        "      weights_o.assign_sub(learning_rate*dw_o)\n",
        "      biases_o.assign_sub(learning_rate*db_o)\n",
        "    \n",
        "    if epoch%50==0:\n",
        "        print(accuracy(y_test.values,logistic_regression(x_test.values)).numpy(),roc_auc(y_test.values,x_test.values))\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.70678335 0.5236426474090884\n",
            "0.81666666 0.5812160617110959\n",
            "0.82448334 0.617173537816167\n",
            "0.82706666 0.6400648076167675\n",
            "0.82781667 0.6528712056074051\n",
            "0.8284 0.6603768774578562\n",
            "0.8283333 0.6659013922238535\n",
            "0.82858336 0.6705259989662685\n",
            "0.82876664 0.674607268369785\n",
            "0.8290667 0.6782006308189156\n",
            "0.82918334 0.6814528514983288\n",
            "0.82923335 0.6844973865172532\n",
            "0.82948333 0.6872240667409417\n",
            "0.82948333 0.6897981966695129\n",
            "0.82953334 0.692128435641504\n",
            "0.8298333 0.6943590636472263\n",
            "0.83033335 0.6965086747076668\n",
            "0.8305167 0.6986112116542422\n",
            "0.83096665 0.7006845690585847\n",
            "0.8308833 0.7025755186676821\n",
            "0.8312 0.7044123840392098\n",
            "0.8311667 0.7062623416178018\n",
            "0.83131665 0.7081042174303107\n",
            "0.83166665 0.7098055302983135\n",
            "0.8318167 0.7115902808315732\n",
            "0.83195 0.7133802362058447\n",
            "0.83206666 0.715086701163092\n",
            "0.8324 0.7167064480766819\n",
            "0.83243334 0.7183778057560993\n",
            "0.83273333 0.719934509423689\n",
            "0.8333167 0.7214643008981422\n",
            "0.83353335 0.7228720013385038\n",
            "0.83393335 0.7240514722357798\n",
            "0.83426666 0.7249951954862869\n",
            "0.83425 0.725887159484511\n",
            "0.83455 0.7265280817310713\n",
            "0.83495 0.7272745407257278\n",
            "0.83531666 0.7281619553724896\n",
            "0.8354167 0.7289430625092262\n",
            "0.83561665 0.7294625013439001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0RIggSeTpuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJEGsZxJWwsJ",
        "colab_type": "code",
        "outputId": "a0159112-3be1-4fc0-eb99-e0caadeff3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%tensorflow_version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currently selected TF version: 1.x\n",
            "Available versions:\n",
            "* 1.x\n",
            "* 2.x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njzdg9_VW2_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}